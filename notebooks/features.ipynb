{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swifter\n",
    "import spacy\n",
    "import ast\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "from itertools import chain\n",
    "from scipy.sparse import issparse\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/df_all.pkl\")\n",
    "df[\"is_cited\"] = (df[\"cited_by_policies_count\"] > 0).astype(int)\n",
    "X, y = df.drop(columns=[\"is_cited\"], inplace=False), df[\"is_cited\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=2137\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractToVecTransformer(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        print(\"Fit: converting abstract to docs\")\n",
    "        abstract_tokens = X[\"abstract\"].swifter.apply(self._abstract_to_token_list)\n",
    "        print(\"Fit: getting unique tokens from dataset\")\n",
    "        flatenned_tokens = list(chain(abstract_tokens))\n",
    "        unique_tokens = np.unique(flatenned_tokens)\n",
    "        print(\"Fit: calculating document frequencies for unique tokens\")\n",
    "        doc_freq = np.array(\n",
    "            list(\n",
    "                map(\n",
    "                    partial(\n",
    "                        self._abstracts_with_token_count, abstracts_col=abstract_tokens\n",
    "                    ),\n",
    "                    unique_tokens,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        print(\"Fit: finding too rare and too frequent tokens\")\n",
    "        self.too_frequent_tokens = unique_tokens[doc_freq > 0.7 * X.shape[0]]\n",
    "        self.too_rare_tokens = unique_tokens[doc_freq < 10]\n",
    "        abstract_tokens = abstract_tokens.swifter.apply(\n",
    "            self._drop_too_frequent_and_too_rare\n",
    "        )\n",
    "        print(\"Fit: fitting tf-idf\")\n",
    "        abstract_tokens = abstract_tokens.swifter.apply(self._merge_token_list_to_text)\n",
    "        self.tfidf = TfidfVectorizer()\n",
    "        self.tfidf.fit(abstract_tokens)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **kwargs):\n",
    "        abstract_col = X[\"abstract\"].swifter.apply(self._abstract_to_token_list)\n",
    "        abstract_col = abstract_col.swifter.apply(self._drop_too_frequent_and_too_rare)\n",
    "        abstract_col = abstract_col.swifter.apply(self._merge_token_list_to_text)\n",
    "        X = X.copy()\n",
    "        X[\"abstract_encoded\"] = abstract_col.swifter.apply(\n",
    "            lambda l: self.tfidf.transform([l])\n",
    "        )\n",
    "        return X\n",
    "\n",
    "    def _abstract_to_token_list(self, abstract):\n",
    "        doc = self.en(abstract)\n",
    "        tokens = [\n",
    "            token.lemma_.lower()\n",
    "            for token in doc\n",
    "            if not token.is_stop\n",
    "            if not token.is_punct\n",
    "        ]\n",
    "        return tokens\n",
    "\n",
    "    def _abstracts_with_token_count(self, token, abstracts_col):\n",
    "        is_token_inside_doc = [\n",
    "            1 if token in abstract else 0 for abstract in abstracts_col.values\n",
    "        ]\n",
    "        return np.sum(is_token_inside_doc)\n",
    "\n",
    "    def _drop_too_frequent_and_too_rare(self, tokens_list):\n",
    "        return list(\n",
    "            filter(\n",
    "                lambda token: token not in self.too_frequent_tokens\n",
    "                and token not in self.too_rare_tokens,\n",
    "                tokens_list,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def _merge_token_list_to_text(self, token_list):\n",
    "        return \" \".join(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = AbstractToVecTransformer()\n",
    "ap.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ap.transform(X_train)\n",
    "X_test = ap.transform(X_test)\n",
    "\n",
    "with open(\"cache/X_train_1.pkl\", \"wb\") as f:\n",
    "    pkl.dump(X_train, f)\n",
    "with open(\"cache/X_test_1.pkl\", \"wb\") as f:\n",
    "    pkl.dump(X_test, f)\n",
    "\n",
    "# with open(\"cache/X_train_1.pkl\", \"rb\") as f:\n",
    "#     X_train = pkl.load(f)\n",
    "# with open(\"cache/X_test_1.pkl\", \"rb\") as f:\n",
    "#     X_test = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RareValuesFromColumnsRemover(TransformerMixin):\n",
    "    def __init__(self, columns=list[str], threshold=2):\n",
    "        self.columns = columns\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.columns_to_mapping = dict()\n",
    "        for column in self.columns:\n",
    "            flat = [el for l in X[column] for el in l]\n",
    "            counter = Counter(flat)\n",
    "            mapping = dict()\n",
    "            for key, val in counter.items():\n",
    "                mapping[key] = key if val >= self.threshold else \"other\"\n",
    "            self.columns_to_mapping[column] = mapping\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **kwargs):\n",
    "        X = X.copy()\n",
    "        for column in self.columns:\n",
    "            X[column] = X[column].swifter.apply(\n",
    "                lambda l: np.unique(\n",
    "                    [self.columns_to_mapping[column].get(el, \"other\") for el in l]\n",
    "                )\n",
    "            )\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"journal\"] = X_train[\"journal\"].fillna(\"No Journal\")\n",
    "X_train[\"journal\"] = X_train[\"journal\"].apply(lambda j: [j])\n",
    "X_test[\"journal\"] = X_test[\"journal\"].fillna(\"No Journal\")\n",
    "X_test[\"journal\"] = X_test[\"journal\"].apply(lambda j: [j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvfcr = RareValuesFromColumnsRemover(\n",
    "    [\"institutions\", \"journal\", \"authors\", \"countries\"]\n",
    ")\n",
    "rvfcr.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = rvfcr.transform(X_train)\n",
    "X_test = rvfcr.transform(X_test)\n",
    "\n",
    "with open(\"cache/X_train_2.pkl\", \"wb\") as f:\n",
    "    pkl.dump(X_train, f)\n",
    "with open(\"cache/X_test_2.pkl\", \"wb\") as f:\n",
    "    pkl.dump(X_test, f)\n",
    "\n",
    "# with open(\"cache/X_train_2.pkl\", \"rb\") as f:\n",
    "#     X_train = pkl.load(f)\n",
    "# with open(\"cache/X_test_2.pkl\", \"rb\") as f:\n",
    "#     X_test = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilabelBinarizerMulticolumn(TransformerMixin):\n",
    "    def __init__(self, columns: list[str]):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.binarizers = dict()\n",
    "        for col in self.columns:\n",
    "            print(f\"Removing NAs from {col}\")\n",
    "            X = X.loc[~X[col].isna()]\n",
    "            mlb = MultiLabelBinarizer()\n",
    "            mlb.fit(X[col])\n",
    "            self.binarizers[col] = mlb\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **kwargs):\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            print(f\"Removing NAs from {col}\")\n",
    "            X = X.loc[~X[col].isna()]\n",
    "            col_transformed = self.binarizers[col].transform(X[col])\n",
    "            col_transformed = list(map(np.array, col_transformed.tolist()))\n",
    "            X[f\"{col}_encoded\"] = col_transformed\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlbmc = MultilabelBinarizerMulticolumn(\n",
    "    [\"institutions\", \"institutions_types\", \"authors\", \"countries\", \"mag_field_of_study\"]\n",
    ")\n",
    "mlbmc.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mlbmc.transform(X_train)\n",
    "X_test = mlbmc.transform(X_test)\n",
    "\n",
    "with open(\"cache/X_train_3.pkl\", \"wb\") as f:\n",
    "    pkl.dump(X_train, f)\n",
    "with open(\"cache/X_test_3.pkl\", \"wb\") as f:\n",
    "    pkl.dump(X_test, f)\n",
    "\n",
    "# with open(\"cache/X_train_3.pkl\", \"rb\") as f:\n",
    "#     X_train = pkl.load(f)\n",
    "# with open(\"cache/X_test_3.pkl\", \"rb\") as f:\n",
    "#     X_test = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnehotEncoderMulticolumn:\n",
    "    def __init__(self, columns: list[str]):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.encoders = dict()\n",
    "        for col in self.columns:\n",
    "            print(f\"Removing NAs from {col}\")\n",
    "            X = X.loc[~X[col].isna()]\n",
    "            oh = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "            column = pd.DataFrame(X[col])\n",
    "            oh.fit(column)\n",
    "            self.encoders[col] = oh\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **kwargs):\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            print(f\"Removing NAs from {col}\")\n",
    "            X = X.loc[~X[col].isna()]\n",
    "            column = pd.DataFrame(X[col])\n",
    "            col_transformed = self.encoders[col].transform(column)\n",
    "            col_transformed = list(map(np.array, col_transformed.todense().tolist()))\n",
    "            X[f\"{col}_encoded\"] = col_transformed\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"journal\"] = X_train[\"journal\"].apply(lambda l: l[0])\n",
    "X_test[\"journal\"] = X_test[\"journal\"].apply(lambda l: l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohemc = OnehotEncoderMulticolumn([\"journal\", \"type\"])\n",
    "ohemc.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ohemc.transform(X_train)\n",
    "X_test = ohemc.transform(X_test)\n",
    "\n",
    "X_train.in_citations_count\n",
    "X_test.in_citations_count\n",
    "X_train.is_open_access = X_train.is_open_access.astype(int)\n",
    "X_test.is_open_access = X_test.is_open_access.astype(int)\n",
    "\n",
    "with open(\"cache/X_train_4.pkl\", \"wb\") as f:\n",
    "    pkl.dump(X_train, f)\n",
    "with open(\"cache/X_test_4.pkl\", \"wb\") as f:\n",
    "    pkl.dump(X_test, f)\n",
    "\n",
    "# with open(\"cache/X_train_4.pkl\", \"rb\") as f:\n",
    "#     X_train = pkl.load(f)\n",
    "# with open(\"cache/X_test_4.pkl\", \"rb\") as f:\n",
    "#     X_test = pkl.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* Wyczyszczenie tekstu x\n",
    "* Usunięcie bardzo częstych i bardzo rzadkich tokenów z tekstu x\n",
    "* Tfidf x\n",
    "* Usunięcie rzadkich afiliacji x\n",
    "* Imputacja journali x\n",
    "* Usunięcie rzadkich journali x\n",
    "* Usunięcie rzadkich autorów x\n",
    "* Usunięcie rzadkich krajów x\n",
    "* Zakodowanie afiliacji - MultilabelBinarizer x\n",
    "* Zakodowanie typów afiliacji - MultilabelBinarizer x\n",
    "* Zakodowanie autorów - MultilabelBinarizer x\n",
    "* Zakodowanie krajów - MultilabelBinarizer x\n",
    "* Kategoria MAG - MultilabelBinarizer x\n",
    "* Zakodowanie journali - OneHot x\n",
    "* Zakodowanie typów dokumentów - OneHot x\n",
    "* Dodanie cytowań w innych paperach x\n",
    "* Dodanie zmiennej czy otwarty dostęp x\n",
    "* Wrzucenie wszystkigo do wektora x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DfToFeatureVector(TransformerMixin):\n",
    "    def __init__(self, ap, mlbmc, ohemc):\n",
    "        self.columns = [\n",
    "            \"in_citations_count\",\n",
    "            \"is_open_access\",\n",
    "            \"abstract_encoded\",\n",
    "            \"institutions_encoded\",\n",
    "            \"institutions_types_encoded\",\n",
    "            \"authors_encoded\",\n",
    "            \"countries_encoded\",\n",
    "            \"mag_field_of_study_encoded\",\n",
    "            \"journal_encoded\",\n",
    "            \"type_encoded\",\n",
    "        ]\n",
    "        self.mlbmc_columns = [\n",
    "            \"institutions\",\n",
    "            \"institutions_types\",\n",
    "            \"authors\",\n",
    "            \"countries\",\n",
    "            \"mag_field_of_study\",\n",
    "        ]\n",
    "        self.ohemc_columns = [\"journal\", \"type\"]\n",
    "        self.ap = ap\n",
    "        self.mlbmc = mlbmc\n",
    "        self.ohemc = ohemc\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        inv_tfidf_dict = {v: k for k, v in ap.tfidf.vocabulary_.items()}\n",
    "        inv_tfidf_dict_items = list(inv_tfidf_dict.items())\n",
    "        inv_tfidf_dict_items.sort(key=lambda x: x[0])\n",
    "        self.abstract_feat_labels = [\n",
    "            f\"abstract_token_{item[1]}\" for item in inv_tfidf_dict_items\n",
    "        ]\n",
    "        all_mlbmc_features = list(\n",
    "            map(\n",
    "                partial(self._get_features_from_mlbmc_binarizer, X=X),\n",
    "                self.mlbmc_columns,\n",
    "            )\n",
    "        )\n",
    "        self.all_mlbmc_features = [el for l in all_mlbmc_features for el in l]\n",
    "        all_ohemc_features = list(\n",
    "            map(\n",
    "                lambda col: ohemc.encoders[col].get_feature_names_out(),\n",
    "                self.ohemc_columns,\n",
    "            )\n",
    "        )\n",
    "        self.all_ohemc_features = [el for l in all_ohemc_features for el in l]\n",
    "        self.labels = (\n",
    "            [\"in_citations_count\", \"is_open_access\"]\n",
    "            + self.abstract_feat_labels\n",
    "            + self.all_mlbmc_features\n",
    "            + self.all_ohemc_features\n",
    "        )\n",
    "\n",
    "    def transform(self, X, y=None, **kwargs):\n",
    "        abstract_col = X[\"abstract\"].reset_index(drop=True)\n",
    "        X = X[self.columns]\n",
    "        X = X.apply(self._stack_row_into_vector, axis=\"columns\")\n",
    "        vals = np.stack(X.values, 0)\n",
    "        df = pd.DataFrame(vals, columns=self.labels)\n",
    "        df[\"abstract\"] = abstract_col\n",
    "        return df\n",
    "\n",
    "    def _stack_row_into_vector(self, row):\n",
    "        row[\"abstract_encoded\"] = row[\"abstract_encoded\"].toarray()[0]\n",
    "        row[\"in_citations_count\"] = np.array([row[\"in_citations_count\"]])\n",
    "        row[\"is_open_access\"] = np.array([row[\"is_open_access\"]])\n",
    "        return np.concatenate(row.values.tolist(), 0)\n",
    "\n",
    "    def _get_features_from_mlbmc_binarizer(self, colname, X):\n",
    "        n = X[colname + \"_encoded\"][0].shape[0]\n",
    "        m = np.eye(n, n)\n",
    "        mlbmc_features = list(\n",
    "            map(lambda l: l[0], mlbmc.binarizers[colname].inverse_transform(m))\n",
    "        )\n",
    "        return list(map(lambda s: colname + \"_\" + s, mlbmc_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2vec = DfToFeatureVector(ap, mlbmc, ohemc)\n",
    "df2vec.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df2vec.transform(X_train)\n",
    "X_test = df2vec.transform(X_test)\n",
    "\n",
    "with open(\"cache/X_train_5.pkl\", \"wb\") as f:\n",
    "    pkl.dump(X_train, f)\n",
    "with open(\"cache/X_test_5.pkl\", \"wb\") as f:\n",
    "    pkl.dump(X_test, f)\n",
    "\n",
    "# with open(\"cache/X_train_5.pkl\", \"rb\") as f:\n",
    "#     X_train = pkl.load(f)\n",
    "# with open(\"cache/X_test_5.pkl\", \"rb\") as f:\n",
    "#     X_test = pkl.load(f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0e7020c842ea58db8265ee26d0d0bae41d1159f80d759db8ce7993036046312"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('badawcze')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
